#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine natbib_authoryear
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Homework 1
\end_layout

\begin_layout Author
Bryan Matsuo and John St.
 John
\end_layout

\begin_layout Enumerate
Version spaces:
\end_layout

\begin_deeper
\begin_layout Enumerate
No the hypothesis space does not have an inductive bias.
 Since the hypothesis space contains every possible labeling of the points,
 viewing any subset of points will not give us information about the labeling
 of the remaining unobserved portion of points.
 A hypothesis class with an inductive bias is one that enables you to make
 assignments to unobserved points and thus learn from a subset of the data
 (page 38 of our textbook).
\end_layout

\begin_layout Enumerate
Any new point may either be grouped with positive instances, or negative
 instances.
 Since the hypothesis space contains every possible grouping of all points,
 it must also be the case that all existing positive and negative instances
 are each in a single group (or the null group if none have been observed).
 Thus there are two possible groupings of the remaining point, with the
 rest of the positives (possibly the null group of positives) or the rest
 of the negatives (possibly the null group of negatives), and thus exactly
 half (1 out of 2) of the version space predicts each outcome.
\end_layout

\end_deeper
\begin_layout Enumerate
Learning disjunctions:
\end_layout

\begin_deeper
\begin_layout Enumerate
A general hypothesis is one that assumes that any unobserved point that
 could consistently be classified as a positive case, is classified that
 way.
 In the base case this will classify all points as positive.
 Any observed positive example will not change our general hypothesis space.
 However a negative example will force us to prune away instance assignments
 from our general hypothesis.
 See Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "Alg:prune"

\end_inset

 for the pseudocode.
 
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Prune(
\begin_inset Formula $X$
\end_inset

)
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "Alg:prune"

\end_inset


\end_layout

\begin_layout Plain Layout
Starting Global General Hypothesis: 
\begin_inset Formula $a_{1}=0\vee a_{1}=1\vee\ldots\vee a_{n}=0\vee a_{n}=1$
\end_inset


\end_layout

\begin_layout Plain Layout
if 
\begin_inset Formula $X\in\{-\}$
\end_inset

: Remove all assigned instances of 
\begin_inset Formula $X$
\end_inset

 from Hypothesis
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
No the most specific hypothesis in this case is not well defined.
 The general algorithm for this would be to ignore negative instances, and
 for each positive ovservation insert the minimal set of instance assignments
 that properly classifies the set of positive observations.
 Consider a simple case with one positive observation that has a set of
 two instance assignments 
\begin_inset Formula $\left\{ a_{1}=1,a_{2}=0\right\} $
\end_inset

.
 In this case we have three equally good specific hypotheses, 
\begin_inset Formula $h_{1}=\left[a_{1}=1\right]$
\end_inset

 , 
\begin_inset Formula $h_{2}=\left[a_{2}=0\right]$
\end_inset

, and 
\begin_inset Formula $h_{3}=\left[a_{1}=1\vee a_{2}=0\right]$
\end_inset

.
 By definition this is not well defined.
\end_layout

\end_deeper
\begin_layout Enumerate
VC Dimension (242 version):
\end_layout

\begin_layout Enumerate
Weka:
\end_layout

\begin_deeper
\begin_layout Enumerate
To seperate out Iris-setosa from the other classes, there is one attribute,
 peta-length, that looks like it results in perfect seperation by itself
 from examining the histogram.
\end_layout

\begin_layout Enumerate
The trimmed tree also has the petal-length atribute as the top node of the
 decision tree.
 This is a good sign.
\end_layout

\begin_layout Enumerate
It looks like petal length or petal width are enough in 1 dimention to seperate
 out Iris-setosa from the others with high confidence.
 This can be clearly seen in the histogram for petal-length, but the seperation
 is a little too close to see the clear divide on the histogram for petal-width.
 Choosing a smaller bin size for the petal-width histogram would solve this
 problem, and it is obvious when examining the points under the visualize
 tab.
\end_layout

\begin_deeper
\begin_layout Enumerate
Side note: Seperating the remaining two classes of irises does not look
 possible with a single dimension.
 In 2d petal-length to petal-width looks like its enough to seperate out
 all three classes in the majority of cases with possibly a few false positives.
 Indeed the J48 decision tree found a fine grained descriminating set of
 rules that are only dependent on those two variables with around a 2% FP
 rate.
\end_layout

\end_deeper
\end_deeper
\end_body
\end_document
