\documentclass[11pt]{article}

\usepackage{fullpage,latexsym,amsthm,amsmath,algorithmic,graphicx,subfigure,color,verbatim,epsfig,fancyhdr,multicol}
%\usepackage[normalmargins]{savetrees}

% Define new commands.
\newtheorem{defn}{Definition}[section]
\newtheorem{conjecture}{conjecture}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{question}{Question}[section]
\newtheorem{proposition}{Proposition}[section]

\begin{document}

% Make the document title.
\title{CMPS 242 - Spring 2011 - Homework assignment \#1}
\author{ {Bryan Matsuo}\\
{Department of Computer Science, UCSC}}
%\date{\today}
\maketitle

%\begin{multicols}{2}
\section*{1 Version spaces}
\subsection*{1(a)}
\subsection*{1(b)}

\section{Learning disjunctions}



\section{VC dimension}

Consider the hypothesis class of homogeneous half-spaces in $\mathcal{R}^d$ where the instance vectors are in $\mathcal{R}^d$ and the hypothesis class $H$ is the set of all $h_w$ having the form $h_w(x) = +1$ if $w \cdot x > 0$, and $-1$ otherwise.
Determine the VC-dimension of homogeneous half-spaces in $\mathcal{R}^d$ as a function of $d$.

This solution will make use of the following proposition provided as a hint.
\begin{proposition}
    \label{prop:lin-comb}
    For any set $S$ of $d+1$ points in $\mathcal{R}^d$, there is at least one point $x \in S$ that can be expressed as a linear combination of the other points in $S$.
\end{proposition}

\begin{lemma}
    The VC-dimension of homogeneous half-spaces in $\mathcal{R}^d$ is at least $d$.
\end{lemma}

\begin{proof}
    Consider the set of instances $X_d = {e_1, e_2, \dots, e_d}$ where $e_i$ is the standard $i$-th basis vector in $\mathcal{R}^d$ (component $i$ of vector $e_i$ is $1$ and the rest are $0$).
    Let $\ell_1, \dots, \ell_d \in \{-1,+1\}$ be a labeling of $X_d$ where $e_i$ recieves label $\ell_i$.

    Consider the vector $w = (\ell_1, \dots, \ell_d)$.
    Notice that $w \cdot e_i = \ell_i$.
    Thus, the hypothesis $h_w$ that predicts using vector $w$ will consistently predict all the labels of instances in $X_d$.

    Due to the arbitrary labels on the instance set $X_d$, we can conclude that the hypothesis class $H$ shatters set $X_d$ and that the VC demension of the hypothesis class is at least $d$.
\end{proof}

\begin{lemma}
    The VC-dimension of homogeneous half-spaces in $\mathcal{R}^d$ is at most $d$.
\end{lemma}

\begin{proof}
    Let $V=(v_0, v_1, \dots, v_d)$ be any set of $d+1$ points in $\mathcal{R}^d$.
    From proposition \ref{prop:lin-comb}, we know that there is a vector $v_k$ in $V$ which can be expressed as a linear combination of the other points in $V$.
    Without loss of generality assume that $v_0$ can be expressed as a linear combination of $v_1, \dots, v_d$.
    That is,
    \[
    v_0 = \sum_{i=1}^{d} a_i v_i
    \].

    Define a labeling $\ell_k$ of point $v_k \in V$ in the following way.
    \[
    \ell_k = \begin{cases}
        +1  &  \text{if } k = 0   \\
        -1  &  \text{if } a_k > 0 \\
        +1  &  \text{if } a_k \leq 0 \\
    \end{cases}
    \].

    Let $w$ be a vector in $\mathcal{R}^d$ and assume that hypothesis $h_w$ is consistent with the labels $\ell_1, \dots, \ell_d$.
    Due to the construction of the labeling, this implies that $a_k (w \cdot v_k) \leq 0$ for $1 \leq k \leq d$.
    Consider now the prediction that $h_w$ makes for instance $v_0$.
    \begin{align*}
        w \cdot v_0 &= w \cdot \bigg( \sum_{i=1}^{d} a_i v_i \bigg) \\
            &= \sum_{i=1}^{d} a_i (w \cdot v_i) \\
            &\leq 0
    \end{align*}
    But the label of $v_0$ is defined as $\ell_0 = +1$.
    So no hypothesis $h_w$ can be consistent with the labeling $\ell_0, \dots, \ell_d$, and thus that the hypothesis class can not shatter the set instance set $V$.
    Because $V$ is an arbitrary set of $d+1$ instances, we have thus shown that the VC-dimension of the hypothesis class is no more than $d$.
\end{proof}

\begin{lemma}
    The VC-dimension of homogeneous half-spaces in $\mathcal{R}^d$ is $d$.
\end{lemma}
\begin{proof}
    This is the direct result of combining the previous two lemmas.
\end{proof}


\section{Computer exercize with Weka}

% Add a bibliography.
%\bibliographystyle{apalike}
%\bibliography{project}

%\end{multicols}

\end{document}
